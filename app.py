import io
import re
import zipfile

import numpy as np
import pandas as pd
import plotly.express as px
import streamlit as st
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain.memory import ConversationBufferWindowMemory
from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_google_genai import ChatGoogleGenerativeAI
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler

# --------------------------------------------------------------------------------------
# --- CONFIGURA√á√ÉO INICIAL ---
# --------------------------------------------------------------------------------------

# --- Configura√ß√£o da Chave de API do Google ---
try:
    # A chave deve estar configurada nos "Secrets" do Streamlit Cloud
    google_api_key = st.secrets["google_ai"]["google_api_key"]
except KeyError:
    st.error(
        "Chave de API do Google n√£o encontrada. Certifique-se de adicion√°-la nos 'Secrets' da sua aplica√ß√£o."
    )
    st.stop()


# --------------------------------------------------------------------------------------
# --- FERRAMENTAS (TOOLS) PARA O AGENTE ---
# --------------------------------------------------------------------------------------


def show_descriptive_stats(*args):
    """
    Gera estat√≠sticas descritivas para todas as colunas de um DataFrame.
    Retorna um dicion√°rio com o resumo estat√≠stico.
    """
    df: pd.DataFrame = st.session_state.df
    stats = df.describe(include="all").to_markdown()
    return {
        "status": "success",
        "data": stats,
        "message": "Estat√≠sticas descritivas geradas.",
    }


def generate_histogram(column: str, *args):
    """
    Gera um histograma interativo Plotly para uma coluna num√©rica espec√≠fica do DataFrame.
    A entrada deve ser o nome da coluna (ex: 'amount', 'v5', 'time').
    """
    df: pd.DataFrame = st.session_state.df
    column = column.lower()

    if column not in df.columns:
        return {
            "status": "error",
            "message": f"Erro: A coluna '{column}' n√£o foi encontrada no DataFrame. Por favor, verifique se o nome est√° correto.",
        }
    if not pd.api.types.is_numeric_dtype(df[column]):
        return {
            "status": "error",
            "message": f"Erro: A coluna '{column}' n√£o √© num√©rica. Forne√ßa uma coluna num√©rica para gerar um histograma.",
        }

    # Usando Plotly Express
    fig = px.histogram(df, x=column, title=f"Distribui√ß√£o de {column}")
    st.session_state.figure_to_display = fig  # Salva a figura na sess√£o
    return {
        "status": "success",
        "message": f"O histograma da coluna '{column}' foi gerado com sucesso. Analise a distribui√ß√£o dos dados e procure por assimetrias ou picos.",
    }


def generate_correlation_heatmap(*args):
    """
    Calcula a matriz de correla√ß√£o entre as vari√°veis num√©ricas do DataFrame
    e gera um mapa de calor (heatmap) interativo Plotly.
    """
    df: pd.DataFrame = st.session_state.df
    numeric_cols = df.select_dtypes(include=np.number).columns
    if len(numeric_cols) < 2:
        return {
            "status": "error",
            "message": "Erro: O DataFrame n√£o tem colunas num√©ricas suficientes para calcular a correla√ß√£o.",
        }

    correlation_matrix = df[numeric_cols].corr()

    # Usando Plotly Express
    fig = px.imshow(
        correlation_matrix,
        text_auto=".2f",
        aspect="auto",
        title="Mapa de Calor da Matriz de Correla√ß√£o",
        color_continuous_scale="RdBu_r",
    )
    fig.update_xaxes(side="top")
    st.session_state.figure_to_display = fig  # Salva a figura na sess√£o
    return {
        "status": "success",
        "message": "O mapa de calor da correla√ß√£o interativo foi gerado. Analise o padr√£o de cores para identificar rela√ß√µes fortes (vermelho/azul escuro) ou fracas (cinza claro).",
    }


def generate_scatter_plot(columns_str: str, *args):
    """
    Gera um gr√°fico de dispers√£o (scatter plot) interativo Plotly para visualizar
    a rela√ß√£o entre duas colunas num√©ricas.
    A entrada DEVE ser uma string contendo os nomes das duas colunas SEPARADAS por um espa√ßo,
    v√≠rgula ou 'e' (ex: 'time, amount' ou 'v1 e v2').
    """
    df: pd.DataFrame = st.session_state.df

    col_names = re.split(r"[,\s]+", columns_str.lower())
    col_names = [col for col in col_names if col and col != "e"]

    if len(col_names) < 2:
        return {
            "status": "error",
            "message": f"Erro de Argumentos: O agente precisa de pelo menos DOIS nomes de coluna para o gr√°fico de dispers√£o. Foi encontrado apenas: {col_names}",
        }

    x_col = col_names[0]
    y_col = col_names[1]

    if x_col not in df.columns or y_col not in df.columns:
        return {
            "status": "error",
            "message": f"Erro: Uma ou ambas as colunas ('{x_col}', '{y_col}') n√£o existem no DataFrame.",
        }

    # Usando Plotly Express
    fig = px.scatter(
        df, x=x_col, y=y_col, title=f"Gr√°fico de Dispers√£o: {x_col} vs {y_col}"
    )
    st.session_state.figure_to_display = fig  # Salva a figura na sess√£o
    return {
        "status": "success",
        "message": f"O gr√°fico de dispers√£o interativo para '{x_col}' vs '{y_col}' foi gerado. Use-o para visualizar a forma e a densidade da rela√ß√£o entre essas vari√°veis.",
    }


def detect_outliers_isolation_forest(*args):
    """
    Detecta anomalias (outliers) no DataFrame usando o algoritmo Isolation Forest.
    A an√°lise √© aplicada √†s colunas V1 a V28, 'time' e 'amount'.
    Retorna o n√∫mero de anomalias detectadas e uma amostra dos outliers.
    """
    try:
        df: pd.DataFrame = st.session_state.df
        feature_cols = [col for col in df.columns if col.startswith("v")] + [
            "time",
            "amount",
        ]

        existing_features = [col for col in feature_cols if col in df.columns]
        if not existing_features:
            return {
                "status": "error",
                "message": "Erro ao detectar anomalias: N√£o foram encontradas colunas V*, 'time' ou 'amount' no DataFrame.",
            }

        df_features = df[existing_features]
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_features)
        model = IsolationForest(contamination=0.01, random_state=42)
        df["anomaly_score"] = model.fit_predict(df_scaled)
        outliers = df[df["anomaly_score"] == -1]

        message = f"O algoritmo Isolation Forest detectou {len(outliers)} transa√ß√µes at√≠picas (outliers)."
        if not outliers.empty:
            message += (
                "\nAmostra das transa√ß√µes detectadas como anomalias:\n"
                + outliers.head().to_markdown(tablefmt="pipe")
            )

        return {"status": "success", "message": message}
    except Exception as e:
        return {"status": "error", "message": f"Erro ao detectar anomalias: {e}"}


def find_clusters_kmeans(n_clusters: str, *args):
    """
    Realiza agrupamento (clustering) nos dados usando o algoritmo K-Means.
    A an√°lise √© aplicada √†s colunas V1 a V28, 'time' e 'amount'.
    A entrada DEVE ser o n√∫mero de clusters desejado (como string, ex: "5").
    Retorna uma descri√ß√£o dos clusters encontrados.
    """
    try:
        n_clusters = int(n_clusters)
    except ValueError:
        return {
            "status": "error",
            "message": f"O n√∫mero de clusters deve ser um n√∫mero inteiro, mas o valor recebido foi '{n_clusters}'.",
        }

    try:
        df: pd.DataFrame = st.session_state.df
        feature_cols = [col for col in df.columns if col.startswith("v")] + [
            "time",
            "amount",
        ]

        existing_features = [col for col in feature_cols if col in df.columns]
        if not existing_features:
            return {
                "status": "error",
                "message": "Erro ao encontrar clusters: N√£o foram encontradas colunas V*, 'time' ou 'amount' no DataFrame.",
            }

        df_features = df[existing_features]
        scaler = StandardScaler()
        df_scaled = scaler.fit_transform(df_features)

        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init="auto")
        df["cluster"] = kmeans.fit_predict(df_scaled)

        cluster_summary = (
            df.groupby("cluster")
            .agg({"amount": ["mean", "min", "max"], "time": ["min", "max"]})
            .to_markdown(tablefmt="pipe")
        )

        message = f"O agrupamento K-Means com {n_clusters} clusters foi conclu√≠do."
        message += "\nCaracter√≠sticas dos Clusters:\n" + cluster_summary

        return {"status": "success", "message": message}
    except Exception as e:
        return {
            "status": "error",
            "message": f"Erro ao realizar o agrupamento com K-Means: {e}",
        }


# --------------------------------------------------------------------------------------
# --- FUN√á√ïES DE CARREGAMENTO DE DADOS E AGENTE ---
# --------------------------------------------------------------------------------------


# Otimiza√ß√£o de Cache: A fun√ß√£o √© decorada com st.cache_data para evitar reprocessar o mesmo arquivo.
# Passamos os bytes do arquivo (file_bytes) em vez do objeto UploadedFile, pois os bytes s√£o "hashable"
# e garantem que o cache funcione corretamente.
@st.cache_data(show_spinner="Processando arquivo...")
def load_and_extract_data(file_bytes, filename):
    """Carrega e prepara o DataFrame a partir de um arquivo CSV ou ZIP."""
    if file_bytes is None:
        return {"status": "error", "message": "Bytes do arquivo n√£o recebidos."}
    uploaded_file = io.BytesIO(file_bytes)

    try:
        if filename.endswith(".zip"):
            with zipfile.ZipFile(uploaded_file, "r") as z:
                # Assume que o CSV √© o primeiro arquivo dentro do ZIP
                with z.open(z.namelist()[0]) as f:
                    df = pd.read_csv(f)
        elif filename.endswith(".csv"):
            df = pd.read_csv(uploaded_file)
        else:
            return {
                "status": "error",
                "message": "Formato de arquivo n√£o suportado. Por favor, envie um arquivo ZIP ou CSV.",
            }

        # Padroniza nomes de colunas para min√∫sculas
        df.columns = [col.lower() for col in df.columns]

        return {
            "status": "success",
            "df": df,
            "message": f"Arquivo '{filename}' carregado com sucesso. DataFrame pronto para an√°lise.",
        }

    except Exception as e:
        return {"status": "error", "message": f"Erro ao processar o arquivo: {e}"}


def initialize_agent(tools_list, system_prompt_text):
    """Inicializa e configura o LangChain Agent com o modelo Gemini Pro."""

    # Modelo alterado para Gemini 2.5 Flash, que √© mais r√°pido e tem cota gratuita maior que o Pro.
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",  # MUDAN√áA: Usando Flash para evitar o erro 429 de cota (mais r√°pido e maior limite)
        google_api_key=google_api_key,
        temperature=0.0,
    )

    prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system_prompt_text),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ]
    )

    memory = ConversationBufferWindowMemory(
        k=5, memory_key="chat_history", return_messages=True
    )

    agent = create_tool_calling_agent(llm, tools_list, prompt)

    # Cria o executor do agente
    agent_executor = AgentExecutor(
        agent=agent, tools=tools_list, verbose=True, memory=memory, max_iterations=15
    )
    return agent_executor


# --------------------------------------------------------------------------------------
# --- INTERFACE DO STREAMLIT ---
# --------------------------------------------------------------------------------------

st.set_page_config(
    page_title="Agente de An√°lise de Dados (Gemini Flash)", layout="wide"
)

st.title("ü§ñ Agente de An√°lise de Dados (EDA) com Gemini Flash")
st.markdown(
    "Envie um arquivo CSV (ou ZIP com CSV) e pergunte ao agente para realizar an√°lises, como correla√ß√£o, estat√≠sticas descritivas ou detec√ß√£o de anomalias."
)

# Inicializa o estado da sess√£o
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None
if "agent_executor" not in st.session_state:
    st.session_state.agent_executor = None
# Vari√°vel de sess√£o para armazenar a figura a ser exibida
if "figure_to_display" not in st.session_state:
    st.session_state.figure_to_display = None

# Sidebar para upload de arquivo
with st.sidebar:
    st.header("Upload do Arquivo de Dados")
    uploaded_file = st.file_uploader(
        "Escolha um arquivo CSV ou ZIP", type=["csv", "zip"]
    )

    if st.button("Carregar Dados e Inicializar Agente") and uploaded_file is not None:
        with st.spinner("Carregando e preparando dados..."):
            # Passa os bytes do arquivo para a fun√ß√£o cacheada
            file_bytes = uploaded_file.getvalue()
            load_result = load_and_extract_data(file_bytes, uploaded_file.name)

        if load_result["status"] == "success":
            st.session_state.df = load_result["df"]

            # Lista de fun√ß√µes a serem convertidas em ferramentas
            tool_functions = [
                show_descriptive_stats,
                generate_histogram,
                generate_correlation_heatmap,
                generate_scatter_plot,
                detect_outliers_isolation_forest,
                find_clusters_kmeans,
            ]

            # Cria a lista de ferramentas LangChain de forma program√°tica
            tools_with_df = [
                Tool(name=func.__name__, description=func.__doc__, func=func)
                for func in tool_functions
            ]

            system_prompt = (
                "Voc√™ √© um agente de An√°lise Explorat√≥ria de Dados (EDA) altamente proficiente. "
                "Sua *PRIMEIRA PRIORIDADE* √© sempre tentar responder √† pergunta do usu√°rio usando uma das ferramentas dispon√≠veis. "
                "*SEMPRE* que o usu√°rio solicitar uma an√°lise de dados (ex: 'correla√ß√£o', 'distribui√ß√£o', 'rela√ß√£o', 'gr√°fico'), voc√™ *DEVE* selecionar a ferramenta apropriada e execut√°-la. "
                "Quando uma ferramenta de gr√°fico √© usada, a figura √© salva e exibida na interface. Voc√™ s√≥ precisa fornecer os insights em texto. "
                "Sua resposta final deve sempre ser em Portugu√™s e oferecer insights."
            )

            st.session_state.agent_executor = initialize_agent(
                tools_with_df, system_prompt
            )
            st.success(
                "Dados carregados e agente inicializado! Voc√™ pode come√ßar a perguntar."
            )

        else:
            st.error(load_result["message"])

    if st.session_state.df is not None:
        st.success(
            f"DataFrame carregado com {len(st.session_state.df)} linhas e {len(st.session_state.df.columns)} colunas."
        )
        st.subheader("Visualiza√ß√£o dos Dados (Amostra)")
        st.dataframe(st.session_state.df.head())


# --- EXIBI√á√ÉO DE MENSAGENS E GR√ÅFICOS ---

# Exibir hist√≥rico de mensagens
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # CORRE√á√ÉO: Renderiza apenas strings. Evita renderizar DataFrames diretamente do hist√≥rico,
        # o que causa o loop infinito de reruns. A exibi√ß√£o de tabelas e gr√°ficos
        # acontece apenas uma vez, no momento da resposta do agente.
        st.markdown(message["content"])

# Tratamento de entrada do usu√°rio
if prompt_input := st.chat_input(
    "Qual an√°lise voc√™ gostaria de fazer? (Ex: 'Gere um mapa de calor da correla√ß√£o')"
):
    with st.chat_message("user"):
        st.markdown(prompt_input)
    st.session_state.messages.append({"role": "user", "content": prompt_input})

    if st.session_state.agent_executor is not None:
        with st.chat_message("assistant"):
            response_container = st.container()

            try:
                full_response = st.session_state.agent_executor.invoke(
                    {"input": prompt_input}
                )
                response_content = full_response["output"]

                # 1. Verifica se h√° um gr√°fico na sess√£o para exibir
                if st.session_state.figure_to_display is not None:
                    response_container.plotly_chart(
                        st.session_state.figure_to_display, use_container_width=True
                    )
                    st.session_state.figure_to_display = (
                        None  # Limpa a sess√£o ap√≥s exibir
                    )

                # Se a resposta for um dicion√°rio, a ferramenta foi usada.
                if isinstance(response_content, dict) and response_content.get(
                    "status"
                ) in ["success", "error"]:
                    # 2. Exibe a mensagem de texto (status, insights, etc.)
                    if "message" in response_content:
                        # Trata mensagens de erro de forma diferente
                        if response_content.get("status") == "error":
                            response_container.error(response_content["message"])
                        else:
                            response_container.markdown(response_content["message"])
                        st.session_state.messages.append(
                            {
                                "role": "assistant",
                                "content": response_content["message"],
                            }
                        )

                    # 3. Exibe dados tabulares, se existirem
                    if "data" in response_content:
                        # SIMPLIFICA√á√ÉO: A ferramenta j√° retorna uma string formatada como Markdown.
                        # Exibimos essa string diretamente em vez de convert√™-la de volta para um DataFrame.
                        # Isso √© mais simples e evita problemas de formata√ß√£o.
                        table_markdown = response_content["data"]
                        response_container.markdown(table_markdown)
                        # Salva a mesma string no hist√≥rico para consist√™ncia.
                        st.session_state.messages.append(
                            {"role": "assistant", "content": table_markdown}
                        )
                else:
                    # Se for uma resposta de texto simples do LLM (sem usar ferramenta)
                    response_container.markdown(str(response_content))
                    st.session_state.messages.append(
                        {"role": "assistant", "content": str(response_content)}
                    )

            except Exception as e:
                # O erro 429 (Quota Exceeded) n√£o √© mais comum com o Gemini Flash, mas mantemos o tratamento.
                error_message = f"Desculpe, ocorreu um erro inesperado na an√°lise: {e}. Por favor, recarregue a p√°gina ou simplifique sua √∫ltima pergunta."
                response_container.error(error_message)
                st.session_state.messages.append(
                    {"role": "assistant", "content": error_message}
                )
